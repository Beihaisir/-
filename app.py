# app.py
import re
from io import BytesIO
from datetime import datetime, date

import numpy as np
import pandas as pd
import streamlit as st


# -----------------------------
# Utilities
# -----------------------------
WEEK_ORDER_ZH = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
WEEK_ORDER_ZH_MAP = {
    "Monday": "å‘¨ä¸€",
    "Tuesday": "å‘¨äºŒ",
    "Wednesday": "å‘¨ä¸‰",
    "Thursday": "å‘¨å››",
    "Friday": "å‘¨äº”",
    "Saturday": "å‘¨å…­",
    "Sunday": "å‘¨æ—¥",
}

DEFAULT_TUANGOU_DATE_CANDIDATES = ["ä¸‹å•æ—¶é—´", "è®¢å•æ—¶é—´", "åˆ›å»ºæ—¶é—´", "æ”¯ä»˜æ—¶é—´"]
DEFAULT_TUANGOU_AMOUNT_CANDIDATES = ["è®¢å•å®æ”¶", "å®æ”¶é‡‘é¢", "å®æ”¶", "ç”¨æˆ·å®ä»˜", "ä»˜æ¬¾é‡‘é¢"]

DEFAULT_XIAOHUI_DATE_CANDIDATES = ["æ ¸é”€æ—¶é—´", "åˆ¸æ ¸é”€æ—¶é—´", "æ ¸é”€å®Œæˆæ—¶é—´", "ä¸‹å•æ—¶é—´"]
DEFAULT_XIAOHUI_AMOUNT_CANDIDATES = ["è®¢å•å®æ”¶", "æ ¸é”€é‡‘é¢", "åˆ¸ç”¨æˆ·å®ä»˜é‡‘é¢", "ç”¨æˆ·å®ä»˜é‡‘é¢", "å®æ”¶é‡‘é¢"]


def pick_first_existing(columns: list[str], candidates: list[str]) -> str | None:
    colset = set(columns)
    for c in candidates:
        if c in colset:
            return c
    return None


def clean_amount_series(s: pd.Series) -> pd.Series:
    """
    Robustly parse currency-like strings to numeric.
    Handles: ï¿¥1,234.56  |  1,234  |  1 234  |  (123) -> -123  |  â€”/ç©º -> NaN
    """
    if s is None:
        return s

    if pd.api.types.is_numeric_dtype(s):
        return pd.to_numeric(s, errors="coerce")

    # Convert to string, normalize
    x = s.astype(str).str.strip()

    # Normalize common "missing" tokens
    x = x.replace(
        {
            "": np.nan,
            "nan": np.nan,
            "None": np.nan,
            "â€”": np.nan,
            "-": np.nan,
            "--": np.nan,
        }
    )

    # Parentheses negative: (123.45) -> -123.45
    x = x.str.replace(r"^\((.*)\)$", r"-\1", regex=True)

    # Remove currency symbols and spaces and commas
    x = x.str.replace(r"[ï¿¥Â¥$,]", "", regex=True)
    x = x.str.replace(r"\s+", "", regex=True)

    # Keep only valid number pattern (optional leading -, digits, optional .digits)
    # If there are other characters, to_numeric will coerce anyway
    return pd.to_numeric(x, errors="coerce")


def coerce_datetime(series: pd.Series) -> pd.Series:
    # Try normal parsing; if many NaT, try with infer and errors
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    return dt


def build_daily_summary(
    tuangou_df: pd.DataFrame,
    xiaohui_df: pd.DataFrame,
    tuangou_date_col: str,
    tuangou_amount_col: str,
    xiaohui_date_col: str,
    xiaohui_amount_col: str,
    merge_how: str = "outer",
) -> pd.DataFrame:
    # ---å›¢è´­---
    tg = tuangou_df.copy()
    tg_dt = coerce_datetime(tg[tuangou_date_col])
    tg["æ—¥æœŸ_dt"] = tg_dt
    tg["æ—¥æœŸ"] = tg["æ—¥æœŸ_dt"].dt.date
    tg_amt = clean_amount_series(tg[tuangou_amount_col])
    tg[tuangou_amount_col] = tg_amt

    tuangou_daily = (
        tg.groupby("æ—¥æœŸ", dropna=False)[tuangou_amount_col]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={tuangou_amount_col: "å›¢è´­è®¢å•å®æ”¶æ±‡æ€»"})
    )

    # ---æ ¸é”€---
    xh = xiaohui_df.copy()
    xh_dt = coerce_datetime(xh[xiaohui_date_col])
    xh["æ—¥æœŸ_dt"] = xh_dt
    xh["æ—¥æœŸ"] = xh["æ—¥æœŸ_dt"].dt.date
    xh_amt = clean_amount_series(xh[xiaohui_amount_col])
    xh[xiaohui_amount_col] = xh_amt

    xiaohui_daily = (
        xh.groupby("æ—¥æœŸ", dropna=False)[xiaohui_amount_col]
        .sum(min_count=1)
        .reset_index()
        .rename(columns={xiaohui_amount_col: "æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"})
    )

    # åˆå¹¶
    merged = pd.merge(tuangou_daily, xiaohui_daily, on="æ—¥æœŸ", how=merge_how)
    merged[["å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"]] = merged[
        ["å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"]
    ].fillna(0)

    merged["æ€»è®¢å•å®æ”¶é‡‘é¢"] = merged["å›¢è´­è®¢å•å®æ”¶æ±‡æ€»"] + merged["æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"]

    # safe ratio
    merged["æ ¸é”€å æ¯”"] = np.where(
        merged["æ€»è®¢å•å®æ”¶é‡‘é¢"] > 0,
        (merged["æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"] / merged["æ€»è®¢å•å®æ”¶é‡‘é¢"] * 100).round(2),
        0.0,
    )

    merged["æ—¥æœŸ"] = pd.to_datetime(merged["æ—¥æœŸ"], errors="coerce")
    merged["æ˜ŸæœŸå‡ _en"] = merged["æ—¥æœŸ"].dt.day_name()
    merged["æ˜ŸæœŸå‡ "] = merged["æ˜ŸæœŸå‡ _en"].map(WEEK_ORDER_ZH_MAP).fillna(merged["æ˜ŸæœŸå‡ _en"])
    merged["æœˆä»½"] = merged["æ—¥æœŸ"].dt.to_period("M").astype(str)

    # æ’åº
    merged = merged.sort_values("æ—¥æœŸ").reset_index(drop=True)

    return merged


def build_weekly_monthly(merged_daily: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    df = merged_daily.copy()

    # Weekly
    # Use English day_name for ordering, then display Chinese
    df["weekday_en"] = df["æ—¥æœŸ"].dt.day_name()
    weekly = (
        df.groupby("weekday_en", dropna=False)
        .agg(
            å›¢è´­è®¢å•å®æ”¶æ±‡æ€»=("å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "sum"),
            æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»=("æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»", "sum"),
            æ€»è®¢å•å®æ”¶é‡‘é¢=("æ€»è®¢å•å®æ”¶é‡‘é¢", "sum"),
            å¤©æ•°=("æ—¥æœŸ", "nunique"),
        )
        .reset_index()
    )
    weekly["æ ¸é”€å æ¯”"] = np.where(
        weekly["æ€»è®¢å•å®æ”¶é‡‘é¢"] > 0,
        (weekly["æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"] / weekly["æ€»è®¢å•å®æ”¶é‡‘é¢"] * 100).round(2),
        0.0,
    )
    weekly["æ˜ŸæœŸå‡ "] = weekly["weekday_en"].map(WEEK_ORDER_ZH_MAP).fillna(weekly["weekday_en"])

    # Order by Monday..Sunday
    cat = pd.Categorical(weekly["weekday_en"], categories=WEEK_ORDER_ZH, ordered=True)
    weekly = weekly.assign(_order=cat).sort_values("_order").drop(columns=["_order"])
    weekly = weekly[["æ˜ŸæœŸå‡ ", "å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»", "æ€»è®¢å•å®æ”¶é‡‘é¢", "æ ¸é”€å æ¯”", "å¤©æ•°"]]

    # Monthly
    monthly = (
        df.groupby("æœˆä»½", dropna=False)
        .agg(
            å›¢è´­è®¢å•å®æ”¶æ±‡æ€»=("å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "sum"),
            æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»=("æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»", "sum"),
            æ€»è®¢å•å®æ”¶é‡‘é¢=("æ€»è®¢å•å®æ”¶é‡‘é¢", "sum"),
            å¤©æ•°=("æ—¥æœŸ", "nunique"),
        )
        .reset_index()
    )
    monthly["æ ¸é”€å æ¯”"] = np.where(
        monthly["æ€»è®¢å•å®æ”¶é‡‘é¢"] > 0,
        (monthly["æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"] / monthly["æ€»è®¢å•å®æ”¶é‡‘é¢"] * 100).round(2),
        0.0,
    )
    monthly = monthly.sort_values("æœˆä»½").reset_index(drop=True)
    monthly = monthly[["æœˆä»½", "å›¢è´­è®¢å•å®æ”¶æ±‡æ€»", "æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»", "æ€»è®¢å•å®æ”¶é‡‘é¢", "æ ¸é”€å æ¯”", "å¤©æ•°"]]

    return weekly, monthly


def format_money_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    out = df.copy()
    for c in cols:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    return out


def export_excel_bytes(
    daily: pd.DataFrame,
    weekly: pd.DataFrame,
    monthly: pd.DataFrame,
    tuangou_sample: pd.DataFrame,
    xiaohui_sample: pd.DataFrame,
) -> BytesIO:
    """
    Write to BytesIO so it can be downloaded in Streamlit (deployment-friendly).
    """
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        daily_export = daily.copy()
        daily_export["æ—¥æœŸ"] = daily_export["æ—¥æœŸ"].dt.strftime("%Y-%m-%d")
        daily_export.to_excel(writer, sheet_name="æ¯æ—¥æ±‡æ€»", index=False)
        weekly.to_excel(writer, sheet_name="æ¯å‘¨æ±‡æ€»", index=False)
        monthly.to_excel(writer, sheet_name="æ¯æœˆæ±‡æ€»", index=False)

        # sample sheets (limit to 1000 rows like your original)
        tuangou_sample.head(1000).to_excel(writer, sheet_name="å›¢è´­æ•°æ®æ ·æœ¬", index=False)
        xiaohui_sample.head(1000).to_excel(writer, sheet_name="æ ¸é”€æ•°æ®æ ·æœ¬", index=False)

    bio.seek(0)
    return bio


def compute_quality_report(df: pd.DataFrame, date_col: str, amount_col: str) -> dict:
    dt = coerce_datetime(df[date_col])
    amt = clean_amount_series(df[amount_col])

    date_total = len(df)
    date_ok = dt.notna().sum()
    amt_ok = amt.notna().sum()

    return {
        "rows": int(date_total),
        "date_ok": int(date_ok),
        "date_bad": int(date_total - date_ok),
        "date_bad_pct": float((date_total - date_ok) / max(date_total, 1) * 100),
        "amt_ok": int(amt_ok),
        "amt_bad": int(date_total - amt_ok),
        "amt_bad_pct": float((date_total - amt_ok) / max(date_total, 1) * 100),
    }


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="è®¢å•å®æ”¶é‡‘é¢ç»Ÿè®¡å·¥å…·", layout="wide")
st.title("ğŸ“Š è®¢å•å®æ”¶é‡‘é¢ç»Ÿè®¡å·¥å…·ï¼ˆStreamlit ç‰ˆï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜", expanded=True):
    st.markdown(
        """
- ä¸Šä¼  **å›¢è´­æˆäº¤æ˜ç»†** ä¸ **æ ¸é”€æ˜ç»†** ä¸¤ä¸ª Excelï¼ˆ.xlsxï¼‰
- ç¨‹åºä¼šè‡ªåŠ¨è¯†åˆ«â€œæ—¥æœŸåˆ—/é‡‘é¢åˆ—â€ï¼Œå¹¶åœ¨é¡µé¢å±•ç¤ºï¼›å¦‚è¯†åˆ«ä¸å¯¹å¯æ‰‹åŠ¨é€‰æ‹©
- å¤„ç†å®Œæˆåå¯ç›´æ¥ä¸‹è½½æ±‡æ€»ç»“æœï¼ˆä¸è½ç›˜ï¼Œé€‚åˆäº‘ç«¯éƒ¨ç½²ï¼‰
"""
    )

colA, colB = st.columns(2)
with colA:
    tuangou_file = st.file_uploader("ä¸Šä¼ ï¼šå›¢è´­æˆäº¤æ˜ç»†ï¼ˆ.xlsxï¼‰", type=["xlsx"], key="tuangou")
with colB:
    xiaohui_file = st.file_uploader("ä¸Šä¼ ï¼šæ ¸é”€æ˜ç»†ï¼ˆ.xlsxï¼‰", type=["xlsx"], key="xiaohui")

merge_how = st.selectbox(
    "åˆå¹¶å£å¾„ï¼ˆæŒ‰æ—¥æœŸï¼‰",
    options=["outer", "inner", "left", "right"],
    index=0,
    help="outer=å…¨éƒ¨æ—¥æœŸï¼›inner=ä¸¤è¾¹éƒ½æœ‰çš„æ—¥æœŸï¼›left=ä»¥å›¢è´­ä¸ºå‡†ï¼›right=ä»¥æ ¸é”€ä¸ºå‡†",
)

if tuangou_file and xiaohui_file:
    # Read previews
    try:
        tuangou_df = pd.read_excel(tuangou_file)
        xiaohui_df = pd.read_excel(xiaohui_file)
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥ï¼š{e}")
        st.stop()

    st.subheader("1) è‡ªåŠ¨è¯†åˆ«åˆ—ï¼ˆå¯æ‰‹åŠ¨è°ƒæ•´ï¼‰")

    c1, c2 = st.columns(2)

    with c1:
        st.markdown("**å›¢è´­æˆäº¤æ˜ç»†**")
        tg_date_auto = pick_first_existing(list(tuangou_df.columns), DEFAULT_TUANGOU_DATE_CANDIDATES)
        tg_amt_auto = pick_first_existing(list(tuangou_df.columns), DEFAULT_TUANGOU_AMOUNT_CANDIDATES)

        tg_date_col = st.selectbox(
            "å›¢è´­ï¼šæ—¥æœŸåˆ—",
            options=list(tuangou_df.columns),
            index=list(tuangou_df.columns).index(tg_date_auto) if tg_date_auto in tuangou_df.columns else 0,
            help="é€šå¸¸æ˜¯ï¼šä¸‹å•æ—¶é—´",
        )
        tg_amt_col = st.selectbox(
            "å›¢è´­ï¼šé‡‘é¢åˆ—",
            options=list(tuangou_df.columns),
            index=list(tuangou_df.columns).index(tg_amt_auto) if tg_amt_auto in tuangou_df.columns else 0,
            help="é€šå¸¸æ˜¯ï¼šè®¢å•å®æ”¶",
        )

        st.caption(f"è‡ªåŠ¨è¯†åˆ«ï¼šæ—¥æœŸ={tg_date_auto or 'æœªè¯†åˆ«'}ï¼›é‡‘é¢={tg_amt_auto or 'æœªè¯†åˆ«'}")

    with c2:
        st.markdown("**æ ¸é”€æ˜ç»†**")
        xh_date_auto = pick_first_existing(list(xiaohui_df.columns), DEFAULT_XIAOHUI_DATE_CANDIDATES)
        xh_amt_auto = pick_first_existing(list(xiaohui_df.columns), DEFAULT_XIAOHUI_AMOUNT_CANDIDATES)

        xh_date_col = st.selectbox(
            "æ ¸é”€ï¼šæ—¥æœŸåˆ—",
            options=list(xiaohui_df.columns),
            index=list(xiaohui_df.columns).index(xh_date_auto) if xh_date_auto in xiaohui_df.columns else 0,
            help="é€šå¸¸æ˜¯ï¼šæ ¸é”€æ—¶é—´ / åˆ¸æ ¸é”€æ—¶é—´",
        )
        xh_amt_col = st.selectbox(
            "æ ¸é”€ï¼šé‡‘é¢åˆ—",
            options=list(xiaohui_df.columns),
            index=list(xiaohui_df.columns).index(xh_amt_auto) if xh_amt_auto in xiaohui_df.columns else 0,
            help="é€šå¸¸æ˜¯ï¼šè®¢å•å®æ”¶ / æ ¸é”€é‡‘é¢",
        )

        st.caption(f"è‡ªåŠ¨è¯†åˆ«ï¼šæ—¥æœŸ={xh_date_auto or 'æœªè¯†åˆ«'}ï¼›é‡‘é¢={xh_amt_auto or 'æœªè¯†åˆ«'}")

    # Data quality checks
    st.subheader("2) æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆè§£æå¤±è´¥ä¼šæç¤ºï¼‰")
    q1, q2 = st.columns(2)
    tg_q = compute_quality_report(tuangou_df, tg_date_col, tg_amt_col)
    xh_q = compute_quality_report(xiaohui_df, xh_date_col, xh_amt_col)

    with q1:
        st.markdown("**å›¢è´­ï¼šæ—¥æœŸ/é‡‘é¢å¯è§£ææƒ…å†µ**")
        st.write(
            {
                "æ€»è¡Œæ•°": tg_q["rows"],
                "æ—¥æœŸè§£æå¤±è´¥(è¡Œ)": tg_q["date_bad"],
                "æ—¥æœŸè§£æå¤±è´¥(%)": round(tg_q["date_bad_pct"], 2),
                "é‡‘é¢è§£æå¤±è´¥(è¡Œ)": tg_q["amt_bad"],
                "é‡‘é¢è§£æå¤±è´¥(%)": round(tg_q["amt_bad_pct"], 2),
            }
        )
        if tg_q["date_bad_pct"] > 5 or tg_q["amt_bad_pct"] > 5:
            st.warning("å›¢è´­æ–‡ä»¶ï¼šè§£æå¤±è´¥æ¯”ä¾‹åé«˜ï¼Œå¯èƒ½åˆ—é€‰é”™æˆ–æ ¼å¼ä¸è§„èŒƒã€‚å»ºè®®æ£€æŸ¥åˆ—é€‰æ‹©ä¸å†…å®¹ã€‚")

    with q2:
        st.markdown("**æ ¸é”€ï¼šæ—¥æœŸ/é‡‘é¢å¯è§£ææƒ…å†µ**")
        st.write(
            {
                "æ€»è¡Œæ•°": xh_q["rows"],
                "æ—¥æœŸè§£æå¤±è´¥(è¡Œ)": xh_q["date_bad"],
                "æ—¥æœŸè§£æå¤±è´¥(%)": round(xh_q["date_bad_pct"], 2),
                "é‡‘é¢è§£æå¤±è´¥(è¡Œ)": xh_q["amt_bad"],
                "é‡‘é¢è§£æå¤±è´¥(%)": round(xh_q["amt_bad_pct"], 2),
            }
        )
        if xh_q["date_bad_pct"] > 5 or xh_q["amt_bad_pct"] > 5:
            st.warning("æ ¸é”€æ–‡ä»¶ï¼šè§£æå¤±è´¥æ¯”ä¾‹åé«˜ï¼Œå¯èƒ½åˆ—é€‰é”™æˆ–æ ¼å¼ä¸è§„èŒƒã€‚å»ºè®®æ£€æŸ¥åˆ—é€‰æ‹©ä¸å†…å®¹ã€‚")

    # Optional date filter (nice to have)
    st.subheader("3) ç”Ÿæˆæ±‡æ€» + ä¸‹è½½")
    st.caption("ç‚¹å‡»åä¼šæŒ‰ä½ é€‰æ‹©çš„åˆ—ä¸åˆå¹¶å£å¾„ç”Ÿæˆæ¯æ—¥/æ¯å‘¨/æ¯æœˆæ±‡æ€»ï¼Œå¹¶æä¾› Excel ä¸‹è½½ã€‚")

    if st.button("ğŸš€ å¼€å§‹å¤„ç†å¹¶ç”ŸæˆæŠ¥è¡¨", type="primary"):
        with st.spinner("å¤„ç†ä¸­..."):
            # build summaries
            daily = build_daily_summary(
                tuangou_df=tuangou_df,
                xiaohui_df=xiaohui_df,
                tuangou_date_col=tg_date_col,
                tuangou_amount_col=tg_amt_col,
                xiaohui_date_col=xh_date_col,
                xiaohui_amount_col=xh_amt_col,
                merge_how=merge_how,
            )
            weekly, monthly = build_weekly_monthly(daily)

            # totals
            total_tuangou = float(daily["å›¢è´­è®¢å•å®æ”¶æ±‡æ€»"].sum())
            total_xiaohui = float(daily["æ ¸é”€è®¢å•å®æ”¶æ±‡æ€»"].sum())
            total_amount = float(daily["æ€»è®¢å•å®æ”¶é‡‘é¢"].sum())
            ratio = (total_xiaohui / total_amount * 100) if total_amount > 0 else 0.0

            # export
            excel_bytes = export_excel_bytes(
                daily=daily,
                weekly=weekly,
                monthly=monthly,
                tuangou_sample=tuangou_df,
                xiaohui_sample=xiaohui_df,
            )

        st.success("å¤„ç†å®Œæˆï¼")

        m1, m2, m3, m4 = st.columns(4)
        m1.metric("å›¢è´­è®¢å•å®æ”¶æ€»é¢", f"{total_tuangou:,.2f}")
        m2.metric("æ ¸é”€è®¢å•å®æ”¶æ€»é¢", f"{total_xiaohui:,.2f}")
        m3.metric("æ€»è®¢å•å®æ”¶é‡‘é¢", f"{total_amount:,.2f}")
        m4.metric("æ ¸é”€å æ¯”(%)", f"{ratio:,.2f}")

        st.markdown("### ğŸ“… æ¯æ—¥æ±‡æ€»")
        st.dataframe(daily, use_container_width=True)

        st.markdown("### ğŸ“† æ¯å‘¨æ±‡æ€»")
        st.dataframe(weekly, use_container_width=True)

        st.markdown("### ğŸ—“ æ¯æœˆæ±‡æ€»")
        st.dataframe(monthly, use_container_width=True)

        filename = f"è®¢å•å®æ”¶æ±‡æ€»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ Excel æ±‡æ€»ç»“æœ",
            data=excel_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

else:
    st.info("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ª .xlsx æ–‡ä»¶ï¼ˆå›¢è´­æˆäº¤æ˜ç»† + æ ¸é”€æ˜ç»†ï¼‰ã€‚")
